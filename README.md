# Titanic â€“ Machine Learning from Disaster  
**Desafio Kaggle | Projeto End-to-End de CiÃªncia de Dados**

---

## ğŸ‡§ğŸ‡· VersÃ£o em PortuguÃªs

## ğŸ“Œ VisÃ£o Geral do Projeto

Este projeto aborda o clÃ¡ssico desafio do Kaggle **â€œTitanic: Machine Learning from Disasterâ€**, com foco principal em:

- AnÃ¡lise ExploratÃ³ria de Dados (EDA) cuidadosa
- Engenharia de atributos explicÃ¡vel
- Tratamento adequado de valores ausentes sem vazamento de dados
- Modelagem com baseline interpretÃ¡vel
- Pipeline de Machine Learning reproduzÃ­vel e limpo

O objetivo **nÃ£o** Ã© maximizar o score no leaderboard, mas demonstrar **mÃ©todo, rigor tÃ©cnico e capacidade de tomada de decisÃ£o baseada em dados**.

---

## ğŸ¯ Objetivo

Prever se um passageiro sobreviveu ao desastre do Titanic a partir de informaÃ§Ãµes demogrÃ¡ficas e socioeconÃ´micas disponÃ­veis **antes do evento**.

VariÃ¡vel alvo:
- `Survived` (0 = NÃ£o sobreviveu, 1 = Sobreviveu)

---

## ğŸ§  Metodologia

### 1ï¸âƒ£ AnÃ¡lise ExploratÃ³ria de Dados (EDA)

Principais observaÃ§Ãµes:

- A sobrevivÃªncia estÃ¡ fortemente associada a sexo, classe social e papel social
- Valores ausentes concentram-se principalmente em:
  - `Age`
  - `Cabin`
  - `Embarked`
- Estrutura familiar e contexto social influenciam a chance de sobrevivÃªncia

As decisÃµes de engenharia de atributos foram guiadas por evidÃªncias observadas no EDA.

---

### 2ï¸âƒ£ Engenharia de Atributos

Foram criadas as seguintes features:

- **FamilySize**  
  FamilySize = SibSp + Parch + 1

- **HasCabin**  
  Indicador binÃ¡rio da existÃªncia de cabine registrada.

- **TitleClean**  
  ExtraÃ­do do nome do passageiro, representando papel social:
  - `Mr`, `Mrs`, `Miss`, `Master`
  - Demais tÃ­tulos agrupados como `Rare`

- **Fare_log**  
  TransformaÃ§Ã£o logarÃ­tmica do valor do ingresso para reduzir assimetria.

---

### 3ï¸âƒ£ ImputaÃ§Ã£o de Idade (Sem Vazamento)

A idade nÃ£o foi imputada por mÃ©dia ou mediana global.  
Foi utilizada a **mediana condicional** baseada em:

- `TitleClean`
- `Pclass`

Vantagens:
- Preserva estrutura social e econÃ´mica
- Evita regras arbitrÃ¡rias
- NÃ£o utiliza a variÃ¡vel alvo
- Evita vazamento de dados

Uma nova coluna `Age_imputed` foi criada, preservando a variÃ¡vel original.

---

### 4ï¸âƒ£ EstratÃ©gia de Modelagem

#### Modelo Base: Ãrvore de DecisÃ£o

Foi utilizada uma **Ãrvore de DecisÃ£o regularizada**, equilibrando interpretabilidade e desempenho.

ParÃ¢metros principais:
DecisionTreeClassifier(max_depth=5, min_samples_leaf=20, random_state=42)

Motivos da escolha:
- Regras explÃ­citas e interpretÃ¡veis
- ImportÃ¢ncia das variÃ¡veis facilmente analisÃ¡vel
- Excelente baseline para dados tabulares

---

### 5ï¸âƒ£ Pipeline e ValidaÃ§Ã£o

Foi utilizado um pipeline completo do `scikit-learn`:

- One-Hot Encoding para variÃ¡veis categÃ³ricas
- VariÃ¡veis numÃ©ricas sem escala
- SeparaÃ§Ã£o treino/validaÃ§Ã£o com estratificaÃ§Ã£o

Resultados:
- AcurÃ¡cia de validaÃ§Ã£o interna â‰ˆ **0.81**
- Baixo overfitting (diferenÃ§a pequena entre treino e validaÃ§Ã£o)

---

### 6ï¸âƒ£ Experimento com Modelo AvanÃ§ado (Opcional)

Foi testado um modelo de **Gradient Boosting**.

Resultado:
- AcurÃ¡cia maior no treino
- Aumento significativo do gap treino-validaÃ§Ã£o
- EvidÃªncia de overfitting

DecisÃ£o:
O modelo nÃ£o foi adotado para a submissÃ£o final, priorizando generalizaÃ§Ã£o e interpretabilidade.

---

## ğŸ“¤ SubmissÃ£o no Kaggle

- Modelo final: **Ãrvore de DecisÃ£o Regularizada**
- Score pÃºblico no Kaggle: **~0.76**

Esse resultado Ã© consistente com:
- Modelagem conservadora
- AusÃªncia de tuning agressivo
- Pipeline correto e sem vazamento

---

## ğŸ“ Estrutura do RepositÃ³rio

data/
  train.csv
  test.csv
src/
  eda.py
  model.py
submission.csv
README.md

---

## ğŸ§© Principais Aprendizados

- Engenharia de atributos pode ser mais importante que modelos complexos
- Modelos interpretÃ¡veis facilitam aprendizado e comunicaÃ§Ã£o
- Nem todo ganho de performance justifica aumento de complexidade
- Entender **por que** o modelo funciona Ã© essencial

---

## ğŸ‘¤ Autor

**Claudio Rodrigues Nunes**  
Estudante de CiÃªncia da ComputaÃ§Ã£o | AnÃ¡lise de Dados e Machine Learning

---
---

## ğŸ‡ºğŸ‡¸ English Version

## ğŸ“Œ Project Overview

This project addresses the classic Kaggle challenge **â€œTitanic: Machine Learning from Disasterâ€**, focusing on:

- Careful Exploratory Data Analysis (EDA)
- Explainable feature engineering
- Proper handling of missing values without data leakage
- Interpretable baseline modeling
- Clean and reproducible machine learning pipeline

The goal is **not** leaderboard optimization, but to demonstrate **solid data science methodology and decision-making**.

---

## ğŸ¯ Objective

Predict whether a passenger survived the Titanic disaster based on demographic and socioeconomic information available **before the event**.

Target variable:
- `Survived` (0 = No, 1 = Yes)

---

## ğŸ§  Methodology

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)

Key insights:

- Survival is strongly associated with gender, passenger class, and social role
- Missing values are concentrated in:
  - `Age`
  - `Cabin`
  - `Embarked`
- Family structure and social context influence survival chances

EDA guided all feature engineering decisions.

---

### 2ï¸âƒ£ Feature Engineering

Engineered features include:

- **FamilySize**  
  FamilySize = SibSp + Parch + 1

- **HasCabin**  
  Binary flag indicating the presence of a cabin record.

- **TitleClean**  
  Extracted from passenger names to represent social roles:
  - `Mr`, `Mrs`, `Miss`, `Master`
  - Other titles grouped as `Rare`

- **Fare_log**  
  Log transformation applied to reduce skewness.

---

### 3ï¸âƒ£ Age Imputation (No Leakage)

Age was not imputed using a global mean or median.  
Instead, **conditional medians** based on:

- `TitleClean`
- `Pclass`

This approach:
- Preserves social and economic structure
- Avoids arbitrary assumptions
- Does not use the target variable
- Prevents data leakage

A separate `Age_imputed` feature was created.

---

### 4ï¸âƒ£ Modeling Strategy

#### Baseline Model: Decision Tree

A **regularized Decision Tree** was used to balance performance and interpretability.

Key parameters:
DecisionTreeClassifier(max_depth=5, min_samples_leaf=20, random_state=42)

---

### 5ï¸âƒ£ Pipeline & Validation

A full `scikit-learn` pipeline was implemented:

- One-Hot Encoding for categorical variables
- Numerical features passed through
- Stratified train/validation split

Results:
- Internal validation accuracy â‰ˆ **0.81**
- Low overfitting

---

### 6ï¸âƒ£ Advanced Model Experiment (Optional)

A **Gradient Boosting** model was tested.

Outcome:
- Higher training accuracy
- Larger trainâ€“validation gap
- Evidence of overfitting

Decision:
The model was not adopted for final submission to preserve generalization.

---

## ğŸ“¤ Kaggle Submission

- Final model: **Regularized Decision Tree**
- Public Kaggle score: **~0.76**

This score reflects:
- Conservative modeling choices
- No aggressive tuning
- Clean and leakage-free pipeline

---

## ğŸ“ Repository Structure

data/
  train.csv
  test.csv
src/
  eda.py
  model.py
submission.csv
README.md

---

## ğŸ§© Key Takeaways

- Feature engineering often matters more than model complexity
- Interpretable models enhance learning and communication
- Not all performance gains justify added complexity
- Understanding why a model works is essential

---

## ğŸ‘¤ Author

**Claudio Rodrigues Nunes**  
Computer Science Student | Data Analysis & Machine Learning
